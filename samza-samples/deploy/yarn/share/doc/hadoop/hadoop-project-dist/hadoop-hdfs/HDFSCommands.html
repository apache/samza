<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- Generated by Apache Maven Doxia at 2015-09-16 -->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 2.6.1 - HDFS Commands Guide</title>
    <style type="text/css" media="all">
      @import url("./css/maven-base.css");
      @import url("./css/maven-theme.css");
      @import url("./css/site.css");
    </style>
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20150916" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      </head>
  <body class="composite">
    <div id="banner">
                  <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="http://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                        <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="http://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                <div class="xleft">
                          <a href="http://www.apache.org/" class="externalLink">Apache</a>
                &gt;
                      <a href="http://hadoop.apache.org/" class="externalLink">Hadoop</a>
                &gt;
                      <a href="../">Apache Hadoop Project Dist POM</a>
                &gt;
                Apache Hadoop 2.6.1
                </div>
            <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://svn.apache.org/repos/asf/hadoop/" class="externalLink">SVN</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                &nbsp;| Last Published: 2015-09-16
              &nbsp;| Version: 2.6.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CommandsManual.html">Hadoop Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Compatibility.html">Hadoop Compatibility</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Superusers.html">Superusers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">HDFS Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">High Availability With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">High Availability With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">HDFS Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/Hftp.html">HFTP</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">C API libhdfs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS REST API</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-hdfs-httpfs/index.html">HttpFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">HDFS NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">HDFS Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">HDFS Support for Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Archival Storage, SSD & Memory</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">MapReduce Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">MapReduce Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibilty between Hadoop 1.x and Hadoop 2.x</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistCp.html">DistCp</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YARN.html">YARN Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">YARN Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">YARN Commands</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerRestart.html">NodeManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/DockerContainerExecutor.html">DockerContainerExecutor</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/releasenotes.html">Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../api/index.html">API docs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CHANGES.txt">Common CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/CHANGES.txt">HDFS CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-mapreduce/CHANGES.txt">MapReduce CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-yarn/CHANGES.txt">YARN CHANGES.txt</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="./images/logos/maven-feather.png"/>
        </a>
                       
                            </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!-- Licensed under the Apache License, Version 2.0 (the "License"); --><!-- you may not use this file except in compliance with the License. --><!-- You may obtain a copy of the License at --><!--  --><!-- http://www.apache.org/licenses/LICENSE-2.0 --><!--  --><!-- Unless required by applicable law or agreed to in writing, software --><!-- distributed under the License is distributed on an "AS IS" BASIS, --><!-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. --><!-- See the License for the specific language governing permissions and --><!-- limitations under the License. See accompanying LICENSE file. --><div class="section">
<h2>HDFS Commands Guide<a name="HDFS_Commands_Guide"></a></h2>
<ul>
<li><a href="#Overview">Overview</a></li>
<li><a href="#User_Commands">User Commands</a>
<ul>
<li><a href="#dfs">dfs</a></li>
<li><a href="#fetchdt">fetchdt</a></li>
<li><a href="#fsck">fsck</a></li>
<li><a href="#version">version</a></li></ul></li>
<li><a href="#Administration_Commands">Administration Commands</a>
<ul>
<li><a href="#balancer">balancer</a></li>
<li><a href="#datanode">datanode</a></li>
<li><a href="#dfsadmin">dfsadmin</a></li>
<li><a href="#mover">mover</a></li>
<li><a href="#namenode">namenode</a></li>
<li><a href="#secondarynamenode">secondarynamenode</a></li></ul></li></ul>
<div class="section">
<h3>Overview<a name="Overview"></a></h3>
<p>All HDFS commands are invoked by the <tt>bin/hdfs</tt> script. Running the hdfs script without any arguments prints the description for all commands.</p>
<p>Usage: <tt>hdfs [--config confdir] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]</tt></p>
<p>Hadoop has an option parsing framework that employs parsing generic options as well as running classes.</p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left"><tt>--config confdir</tt></td>
<td align="left">Overwrites the default Configuration directory. Default is <tt>$<a name="HADOOP_HOME">HADOOP_HOME</a>/conf</tt>.</td></tr>
<tr class="a">
<td align="left">GENERIC_OPTIONS</td>
<td align="left">The common set of options supported by multiple commands. Full list is <a href="../hadoop-common/CommandsManual.html#Generic_Options">here</a>.</td></tr>
<tr class="b">
<td align="left">COMMAND_OPTIONS</td>
<td align="left">Various commands with their options are described in the following sections. The commands have been grouped into <a href="#User_Commands"></a> and <a href="#Administration_Commands"></a>.</td></tr></table></div>
<div class="section">
<h3>User Commands<a name="User_Commands"></a></h3>
<p>Commands useful for users of a hadoop cluster.</p>
<div class="section">
<h4><tt>dfs</tt><a name="dfs"></a></h4>
<p>Usage: <tt>hdfs dfs [GENERIC_OPTIONS] [COMMAND_OPTIONS]</tt></p>
<p>Run a filesystem command on the file system supported in Hadoop. The various COMMAND_OPTIONS can be found at <a href="../hadoop-common/FileSystemShell.html">File System Shell Guide</a>.</p></div>
<div class="section">
<h4><tt>fetchdt</tt><a name="fetchdt"></a></h4>
<p>Gets Delegation Token from a NameNode. See <a href="./HdfsUserGuide.html#fetchdt">fetchdt</a> for more info.</p>
<p>Usage: <tt>hdfs fetchdt [GENERIC_OPTIONS] [--webservice &lt;namenode_http_addr&gt;] &lt;path&gt; </tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left"><i>fileName</i></td>
<td align="left">File name to store the token into.</td></tr>
<tr class="a">
<td align="left">--webservice <i>https_address</i></td>
<td align="left">use http protocol instead of RPC</td></tr></table></div>
<div class="section">
<h4><tt>fsck</tt><a name="fsck"></a></h4>
<p>Runs a HDFS filesystem checking utility. See <a href="./HdfsUserGuide.html#fsck">fsck</a> for more info.</p>
<p>Usage: <tt>hdfs fsck [GENERIC_OPTIONS] &lt;path&gt; [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]] [-includeSnapshots]</tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left"><i>path</i></td>
<td align="left">Start checking from this path.</td></tr>
<tr class="a">
<td align="left">-move</td>
<td align="left">Move corrupted files to /lost+found</td></tr>
<tr class="b">
<td align="left">-delete</td>
<td align="left">Delete corrupted files.</td></tr>
<tr class="a">
<td align="left">-files</td>
<td align="left">Print out files being checked.</td></tr>
<tr class="b">
<td align="left">-openforwrite</td>
<td align="left">Print out files opened for write.</td></tr>
<tr class="a">
<td align="left">-includeSnapshots</td>
<td align="left">Include snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it.</td></tr>
<tr class="b">
<td align="left">-list-corruptfileblocks</td>
<td align="left">Print out list of missing blocks and files they belong to.</td></tr>
<tr class="a">
<td align="left">-blocks</td>
<td align="left">Print out block report.</td></tr>
<tr class="b">
<td align="left">-locations</td>
<td align="left">Print out locations for every block.</td></tr>
<tr class="a">
<td align="left">-racks</td>
<td align="left">Print out network topology for data-node locations.</td></tr></table></div>
<div class="section">
<h4><tt>version</tt><a name="version"></a></h4>
<p>Prints the version.</p>
<p>Usage: <tt>hdfs version</tt></p></div></div>
<div class="section">
<h3>Administration Commands<a name="Administration_Commands"></a></h3>
<p>Commands useful for administrators of a hadoop cluster.</p>
<div class="section">
<h4><tt>balancer</tt><a name="balancer"></a></h4>
<p>Runs a cluster balancing utility. An administrator can simply press Ctrl-C to stop the rebalancing process. See <a href="./HdfsUserGuide.html#Balancer">Balancer</a> for more details.</p>
<p>Usage: <tt>hdfs balancer [-threshold &lt;threshold&gt;] [-policy &lt;policy&gt;]</tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<td align="left">Description</td></tr>
<tr class="b">
<td align="left">-threshold <i>threshold</i></td>
<td align="left">Percentage of disk capacity. This overwrites the default threshold.</td></tr>
<tr class="a">
<td align="left">-policy <i>policy</i></td>
<td align="left"><tt>datanode</tt> (default): Cluster is balanced if each datanode is balanced. &#xa0;<br /><tt>blockpool</tt>: Cluster is balanced if each block pool in each datanode is balanced.</td></tr></table>
<p>Note that the <tt>blockpool</tt> policy is more strict than the <tt>datanode</tt> policy.</p></div>
<div class="section">
<h4><tt>datanode</tt><a name="datanode"></a></h4>
<p>Runs a HDFS datanode.</p>
<p>Usage: <tt>hdfs datanode [-regular | -rollback | -rollingupgrace rollback]</tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left">-regular</td>
<td align="left">Normal datanode startup (default).</td></tr>
<tr class="a">
<td align="left">-rollback</td>
<td align="left">Rollback the datanode to the previous version. This should be used after stopping the datanode and distributing the old hadoop version.</td></tr>
<tr class="b">
<td align="left">-rollingupgrade rollback</td>
<td align="left">Rollback a rolling upgrade operation.</td></tr></table></div>
<div class="section">
<h4><tt>dfsadmin</tt><a name="dfsadmin"></a></h4>
<p>Runs a HDFS dfsadmin client.</p>
<div class="source">
<pre>   Usage: hdfs dfsadmin [GENERIC_OPTIONS]
          [-report [-live] [-dead] [-decommissioning]]
          [-safemode enter | leave | get | wait]
          [-saveNamespace]
          [-rollEdits]
          [-restoreFailedStorage true|false|check]
          [-refreshNodes]
          [-setQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;]
          [-clrQuota &lt;dirname&gt;...&lt;dirname&gt;]
          [-setSpaceQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;]
          [-clrSpaceQuota &lt;dirname&gt;...&lt;dirname&gt;]
          [-setStoragePolicy &lt;path&gt; &lt;policyName&gt;]
          [-getStoragePolicy &lt;path&gt;]
          [-finalizeUpgrade]
          [-rollingUpgrade [&lt;query&gt;|&lt;prepare&gt;|&lt;finalize&gt;]]
          [-metasave filename]
          [-refreshServiceAcl]
          [-refreshUserToGroupsMappings]
          [-refreshSuperUserGroupsConfiguration]
          [-refreshCallQueue]
          [-refresh &lt;host:ipc_port&gt; &lt;key&gt; [arg1..argn]]
          [-printTopology]
          [-refreshNamenodes datanodehost:port]
          [-deleteBlockPool datanode-host:port blockpoolId [force]]
          [-setBalancerBandwidth &lt;bandwidth in bytes per second&gt;]
          [-allowSnapshot &lt;snapshotDir&gt;]
          [-disallowSnapshot &lt;snapshotDir&gt;]
          [-fetchImage &lt;local directory&gt;]
          [-shutdownDatanode &lt;datanode_host:ipc_port&gt; [upgrade]]
          [-getDatanodeInfo &lt;datanode_host:ipc_port&gt;]
          [-triggerBlockReport [-incremental] &lt;datanode_host:ipc_port&gt;]
          [-help [cmd]]</pre></div>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left">-report [-live] [-dead] [-decommissioning]</td>
<td align="left">Reports basic filesystem information and statistics. Optional flags may be used to filter the list of displayed DataNodes.</td></tr>
<tr class="a">
<td align="left">-safemode enter|leave|get|wait</td>
<td align="left">Safe mode maintenance command. Safe mode is a Namenode state in which it &#xa0;<br />1. does not accept changes to the name space (read-only) &#xa0;<br />2. does not replicate or delete blocks. &#xa0;<br />Safe mode is entered automatically at Namenode startup, and leaves safe mode automatically when the configured minimum percentage of blocks satisfies the minimum replication condition. Safe mode can also be entered manually, but then it can only be turned off manually as well.</td></tr>
<tr class="b">
<td align="left">-saveNamespace</td>
<td align="left">Save current namespace into storage directories and reset edits log. Requires safe mode.</td></tr>
<tr class="a">
<td align="left">-rollEdits</td>
<td align="left">Rolls the edit log on the active NameNode.</td></tr>
<tr class="b">
<td align="left">-restoreFailedStorage true|false|check</td>
<td align="left">This option will turn on/off automatic attempt to restore failed storage replicas. If a failed storage becomes available again the system will attempt to restore edits and/or fsimage during checkpoint. 'check' option will return current setting.</td></tr>
<tr class="a">
<td align="left">-refreshNodes</td>
<td align="left">Re-read the hosts and exclude files to update the set of Datanodes that are allowed to connect to the Namenode and those that should be decommissioned or recommissioned.</td></tr>
<tr class="b">
<td align="left">-setQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;</td>
<td align="left">See <a href="../hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands">HDFS Quotas Guide</a> for the detail.</td></tr>
<tr class="a">
<td align="left">-clrQuota &lt;dirname&gt;...&lt;dirname&gt;</td>
<td align="left">See <a href="../hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands">HDFS Quotas Guide</a> for the detail.</td></tr>
<tr class="b">
<td align="left">-setSpaceQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;</td>
<td align="left">See <a href="../hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands">HDFS Quotas Guide</a> for the detail.</td></tr>
<tr class="a">
<td align="left">-clrSpaceQuota &lt;dirname&gt;...&lt;dirname&gt;</td>
<td align="left">See <a href="../hadoop-hdfs/HdfsQuotaAdminGuide.html#Administrative_Commands">HDFS Quotas Guide</a> for the detail.</td></tr>
<tr class="b">
<td align="left">-setStoragePolicy &lt;path&gt; &lt;policyName&gt;</td>
<td align="left">Set a storage policy to a file or a directory.</td></tr>
<tr class="a">
<td align="left">-getStoragePolicy &lt;path&gt;</td>
<td align="left">Get the storage policy of a file or a directory.</td></tr>
<tr class="b">
<td align="left">-finalizeUpgrade</td>
<td align="left">Finalize upgrade of HDFS. Datanodes delete their previous version working directories, followed by Namenode doing the same. This completes the upgrade process.</td></tr>
<tr class="a">
<td align="left">-rollingUpgrade [&lt;query&gt;|&lt;prepare&gt;|&lt;finalize&gt;]</td>
<td align="left">See <a href="../hadoop-hdfs/HdfsRollingUpgrade.html#dfsadmin_-rollingUpgrade">Rolling Upgrade document</a> for the detail.</td></tr>
<tr class="b">
<td align="left">-metasave filename</td>
<td align="left">Save Namenode's primary data structures to <i>filename</i> in the directory specified by hadoop.log.dir property. <i>filename</i> is overwritten if it exists. <i>filename</i> will contain one line for each of the following&#xa0;<br />1. Datanodes heart beating with Namenode&#xa0;<br />2. Blocks waiting to be replicated&#xa0;<br />3. Blocks currently being replicated&#xa0;<br />4. Blocks waiting to be deleted</td></tr>
<tr class="a">
<td align="left">-refreshServiceAcl</td>
<td align="left">Reload the service-level authorization policy file.</td></tr>
<tr class="b">
<td align="left">-refreshUserToGroupsMappings</td>
<td align="left">Refresh user-to-groups mappings.</td></tr>
<tr class="a">
<td align="left">-refreshSuperUserGroupsConfiguration</td>
<td align="left">Refresh superuser proxy groups mappings</td></tr>
<tr class="b">
<td align="left">-refreshCallQueue</td>
<td align="left">Reload the call queue from config.</td></tr>
<tr class="a">
<td align="left">-refresh &lt;host:ipc_port&gt; &lt;key&gt; [arg1..argn]</td>
<td align="left">Triggers a runtime-refresh of the resource specified by &lt;key&gt; on &lt;host:ipc_port&gt;. All other args after are sent to the host.</td></tr>
<tr class="b">
<td align="left">-printTopology</td>
<td align="left">Print a tree of the racks and their nodes as reported by the Namenode</td></tr>
<tr class="a">
<td align="left">-refreshNamenodes datanodehost:port</td>
<td align="left">For the given datanode, reloads the configuration files, stops serving the removed block-pools and starts serving new block-pools.</td></tr>
<tr class="b">
<td align="left">-deleteBlockPool datanode-host:port blockpoolId [force]</td>
<td align="left">If force is passed, block pool directory for the given blockpool id on the given datanode is deleted along with its contents, otherwise the directory is deleted only if it is empty. The command will fail if datanode is still serving the block pool. Refer to refreshNamenodes to shutdown a block pool service on a datanode.</td></tr>
<tr class="a">
<td align="left">-setBalancerBandwidth &lt;bandwidth in bytes per second&gt;</td>
<td align="left">Changes the network bandwidth used by each datanode during HDFS block balancing. &lt;bandwidth&gt; is the maximum number of bytes per second that will be used by each datanode. This value overrides the dfs.balance.bandwidthPerSec parameter.&#xa0;<br />NOTE: The new value is not persistent on the DataNode.</td></tr>
<tr class="b">
<td align="left">-allowSnapshot &lt;snapshotDir&gt;</td>
<td align="left">Allowing snapshots of a directory to be created. If the operation completes successfully, the directory becomes snapshottable.</td></tr>
<tr class="a">
<td align="left">-disallowSnapshot &lt;snapshotDir&gt;</td>
<td align="left">Disallowing snapshots of a directory to be created. All snapshots of the directory must be deleted before disallowing snapshots.</td></tr>
<tr class="b">
<td align="left">-fetchImage &lt;local directory&gt;</td>
<td align="left">Downloads the most recent fsimage from the NameNode and saves it in the specified local directory.</td></tr>
<tr class="a">
<td align="left">-shutdownDatanode &lt;datanode_host:ipc_port&gt; [upgrade]</td>
<td align="left">Submit a shutdown request for the given datanode. See <a href="./HdfsRollingUpgrade.html#dfsadmin_-shutdownDatanode">Rolling Upgrade document</a> for the detail.</td></tr>
<tr class="b">
<td align="left">-getDatanodeInfo &lt;datanode_host:ipc_port&gt;</td>
<td align="left">Get the information about the given datanode. See <a href="./HdfsRollingUpgrade.html#dfsadmin_-getDatanodeInfo">Rolling Upgrade document</a> for the detail.</td></tr>
<tr class="a">
<td align="left">-triggerBlockReport [-incremental] &lt;datanode_host:ipc_port&gt;</td>
<td align="left">Trigger a block report for the given datanode. If 'incremental' is specified, it will be otherwise, it will be a full block report.</td></tr>
<tr class="b">
<td align="left">-help [cmd]</td>
<td align="left">Displays help for the given command or all commands if none is specified.</td></tr></table></div>
<div class="section">
<h4><tt>mover</tt><a name="mover"></a></h4>
<p>Runs the data migration utility. See <a href="./ArchivalStorage.html#Mover_-_A_New_Data_Migration_Tool">Mover</a> for more details.</p>
<p>Usage: <tt>hdfs mover [-p &lt;files/dirs&gt; | -f &lt;local file name&gt;]</tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left">-p &lt;files/dirs&gt;</td>
<td align="left">Specify a space separated list of HDFS files/dirs to migrate.</td></tr>
<tr class="a">
<td align="left">-f &lt;local file&gt;</td>
<td align="left">Specify a local file containing a list of HDFS files/dirs to migrate.</td></tr></table>
<p>Note that, when both -p and -f options are omitted, the default path is the root directory.</p></div>
<div class="section">
<h4><tt>namenode</tt><a name="namenode"></a></h4>
<p>Runs the namenode. More info about the upgrade, rollback and finalize is at <a href="./HdfsUserGuide.html#Upgrade_and_Rollback">Upgrade Rollback</a>.</p>
<div class="source">
<pre>   Usage: hdfs namenode [-backup] |
          [-checkpoint] |
          [-format [-clusterid cid ] [-force] [-nonInteractive] ] |
          [-upgrade [-clusterid cid] [-renameReserved&lt;k-v pairs&gt;] ] |
          [-upgradeOnly [-clusterid cid] [-renameReserved&lt;k-v pairs&gt;] ] |
          [-rollback] |
          [-rollingUpgrade &lt;downgrade|rollback&gt; ] |
          [-finalize] |
          [-importCheckpoint] |
          [-initializeSharedEdits] |
          [-bootstrapStandby] |
          [-recover [-force] ] |
          [-metadataVersion ]</pre></div>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left">-backup</td>
<td align="left">Start backup node.</td></tr>
<tr class="a">
<td align="left">-checkpoint</td>
<td align="left">Start checkpoint node.</td></tr>
<tr class="b">
<td align="left">-format [-clusterid cid] [-force] [-nonInteractive]</td>
<td align="left">Formats the specified NameNode. It starts the NameNode, formats it and then shut it down. -force option formats if the name directory exists. -nonInteractive option aborts if the name directory exists, unless -force option is specified.</td></tr>
<tr class="a">
<td align="left">-upgrade [-clusterid cid] [-renameReserved&lt;k-v pairs&gt;]</td>
<td align="left">Namenode should be started with upgrade option after the distribution of new Hadoop version.</td></tr>
<tr class="b">
<td align="left">-upgradeOnly [-clusterid cid] [-renameReserved&lt;k-v pairs&gt;]</td>
<td align="left">Upgrade the specified NameNode and then shutdown it.</td></tr>
<tr class="a">
<td align="left">-rollback</td>
<td align="left">Rollback the NameNode to the previous version. This should be used after stopping the cluster and distributing the old Hadoop version.</td></tr>
<tr class="b">
<td align="left">-rollingUpgrade &lt;downgrade|rollback|started&gt;</td>
<td align="left">See <a href="./HdfsRollingUpgrade.html#NameNode_Startup_Options">Rolling Upgrade document</a> for the detail.</td></tr>
<tr class="a">
<td align="left">-finalize</td>
<td align="left">Finalize will remove the previous state of the files system. Recent upgrade will become permanent. Rollback option will not be available anymore. After finalization it shuts the NameNode down.</td></tr>
<tr class="b">
<td align="left">-importCheckpoint</td>
<td align="left">Loads image from a checkpoint directory and save it into the current one. Checkpoint dir is read from property fs.checkpoint.dir</td></tr>
<tr class="a">
<td align="left">-initializeSharedEdits</td>
<td align="left">Format a new shared edits dir and copy in enough edit log segments so that the standby NameNode can start up.</td></tr>
<tr class="b">
<td align="left">-bootstrapStandby</td>
<td align="left">Allows the standby NameNode's storage directories to be bootstrapped by copying the latest namespace snapshot from the active NameNode. This is used when first configuring an HA cluster.</td></tr>
<tr class="a">
<td align="left">-recover [-force]</td>
<td align="left">Recover lost metadata on a corrupt filesystem. See <a href="./HdfsUserGuide.html#Recovery_Mode">HDFS User Guide</a> for the detail.</td></tr>
<tr class="b">
<td align="left">-metadataVersion</td>
<td align="left">Verify that configured directories exist, then print the metadata versions of the software and the image.</td></tr></table></div>
<div class="section">
<h4><tt>secondarynamenode</tt><a name="secondarynamenode"></a></h4>
<p>Runs the HDFS secondary namenode. See <a href="./HdfsUserGuide.html#Secondary_NameNode">Secondary Namenode</a> for more info.</p>
<p>Usage: <tt>hdfs secondarynamenode [-checkpoint [force]] | [-format] | [-geteditsize]</tt></p>
<table border="1" class="bodyTable">
<tr class="a">
<th align="left">COMMAND_OPTION</th>
<th align="left">Description</th></tr>
<tr class="b">
<td align="left">-checkpoint [force]</td>
<td align="left">Checkpoints the SecondaryNameNode if EditLog size &gt;= fs.checkpoint.size. If <tt>force</tt> is used, checkpoint irrespective of EditLog size.</td></tr>
<tr class="a">
<td align="left">-format</td>
<td align="left">Format the local storage during startup.</td></tr>
<tr class="b">
<td align="left">-geteditsize</td>
<td align="left">Prints the number of uncheckpointed transactions on the NameNode.</td></tr></table></div></div></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">&#169;            2015
              Apache Software Foundation
            
                       - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a></div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
